{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthText(Dataset):\n",
    "    def __init__(self, target_size, data_path=None):\n",
    "        assert data_path is not None\n",
    "\n",
    "        self.target_size = target_size\n",
    "        self.data_path = data_path\n",
    "        # type of transforms is list of functions\n",
    "\n",
    "        gt = scio.loadmat(os.path.join(self.data_path, 'gt.mat'))\n",
    "        # type: dict, keys: '__header__', '__version__', '__globals__', 'charBB', 'wordBB', 'imnames', 'txt'\n",
    "        # Their types are all < numpy.ndarray > and sizes are all (1, 858750) before slicing\n",
    "        self.name = gt['imnames'][0]\n",
    "        self.char = gt['charBB'][0]\n",
    "        self.word = gt['wordBB'][0]\n",
    "        # After slicing, their sizes are all 858750\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def get_image(self, path):\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.array(image)\n",
    "        return image\n",
    "\n",
    "    # transpose bboxes for pre-processing\n",
    "    def transpose_bboxes(self, bboxes):\n",
    "        src = bboxes.copy()\n",
    "        if len(np.shape(src)) == 2:\n",
    "            src = src[:, :, np.newaxis]\n",
    "        res = src.transpose((2, 1, 0))\n",
    "        return res\n",
    "\n",
    "    ###### Cropping one word in each image (Augmentation) ######\n",
    "    def crop_one_word(self, img, word_bboxes, char_bboxes):\n",
    "        src = word_bboxes.copy()\n",
    "        len = src.size(0)\n",
    "        ind = random.randint(0,len)\n",
    "\n",
    "        img_h, img_w = img.shape[0], img.shape[1]\n",
    "\n",
    "        x_1,y_1 = src(ind,0,:)\n",
    "        \n",
    "        h = src(ind,3,1) - src(ind,0,1)\n",
    "        w = src(ind,1,0) - src(ind,0,0)\n",
    "\n",
    "        crop_image = img[x_1: x_1 + w,\n",
    "                      y_1: y_1 + h, :]\n",
    "        resize_image = cv2.resize(crop_image, dsize=(\n",
    "             img_w/w, img_h/h), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        word_gt = torch.tensor([[[0,0],[w-1,0],[w-1,h-1],[0,h-1]],np.newaxis])\n",
    "        \n",
    "        char_bboxes(ind,:,0) = (char_bboxes(ind,:,0) * w /img_w) - w\n",
    "        char_bboxes(ind,:,1) = (char_bboxes(ind,:,1) * h /img_h) - h\n",
    "\n",
    "        return resize_image, word_gt, char_bboxes\n",
    "\n",
    "    def clipping_bboxes(self, bbox, scale):\n",
    "        # bbox: K x 2\n",
    "        # ICDAR2013: K = 2, ICDAR2015: K = 4 , etc.\n",
    "        src = bbox\n",
    "        # when bbox: (2, K)\n",
    "        if np.shape(src)[1] != 2:\n",
    "            src = bbox.transpose((1, 0))\n",
    "\n",
    "        x = [point[0] for point in src]\n",
    "        y = [point[1] for point in src]\n",
    "\n",
    "        center_x, center_y = np.mean(np.array(x)), np.mean(np.array(y))\n",
    "        # shapely module\n",
    "        src = Polygon(src)\n",
    "        center = geometry.Point(center_x, center_y)\n",
    "        distance_from_center_to_poly = src.exterior.distance(center)\n",
    "        shrink_distance = distance_from_center_to_poly*scale\n",
    "        # clip adaptively to the input\n",
    "        temp = Polygon(src.buffer(-shrink_distance))\n",
    "        temp = list(temp.exterior.coords)\n",
    "\n",
    "        res = []\n",
    "        for xy in temp:\n",
    "            if xy not in res:\n",
    "                res.append(xy)\n",
    "        res = np.array(res).astype(np.int32)\n",
    "        return res\n",
    "\n",
    "    def char_mask(self, img_size, bboxes):\n",
    "        # bboxes : N x 4 x 2\n",
    "        mask = np.zeros(img_size, dtype=np.uint8)\n",
    "        temp = bboxes.copy()\n",
    "\n",
    "        shrink = []\n",
    "        for i in range(np.shape(temp)[0]):\n",
    "            point = temp[i, :, :]\n",
    "            point = self.clipping_bboxes(point, scale=0.25)  # default = 0.2\n",
    "\n",
    "            if len(point) > 0:\n",
    "                shrink.append(point.astype(np.int32))\n",
    "        # shrink: list of reduced char boxes\n",
    "        if len(shrink) >= 1:\n",
    "            res = cv2.fillPoly(mask, shrink, 1)\n",
    "\n",
    "        else:\n",
    "            res = mask\n",
    "\n",
    "        res = res.astype(np.float32)\n",
    "        return res\n",
    "\n",
    "    def word_mask(self, img_size, bboxes):\n",
    "        # bboxes : N x 4 x 2\n",
    "\n",
    "        # default:\n",
    "        scales = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "        # scales = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        temp = bboxes.copy()\n",
    "        res = np.zeros(img_size, dtype=np.float32)\n",
    "        for scale in scales:\n",
    "            shrink = []\n",
    "            mask = np.zeros(img_size, dtype=np.uint8)\n",
    "\n",
    "            for i in range(temp.shape[0]):\n",
    "                # point: a box coordinate 4 x 2\n",
    "                point = temp[i, :, :]\n",
    "                point_copy = self.clipping_bboxes(point, scale=scale)\n",
    "                # 비어 있는 point 제거\n",
    "                if len(point_copy) > 0:\n",
    "                    shrink.append(point_copy.astype(np.int32))\n",
    "                    # shrink: list of reduced char boxes\n",
    "            res_slice = cv2.fillPoly(mask, shrink, 1)\n",
    "            res += res_slice.astype(np.float32).copy()\n",
    "\n",
    "        res /= len(scales)\n",
    "        return res\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.data_path, self.name[index][0])\n",
    "        image = self.get_image(image_path)\n",
    "        # image: uint8\n",
    "\n",
    "        chars = self.char[index]\n",
    "        words = self.word[index]\n",
    "\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "\n",
    "        chars = self.transpose_bboxes(chars)\n",
    "        words = self.transpose_bboxes(words)\n",
    "\n",
    "        \"추가\"\n",
    "        #####\n",
    "        image, words, chars = crop_one_word(image, words, chars)\n",
    "        #####\n",
    "        \n",
    "        image, words, chars = RandomScalewithCoords()(image, words, chars)\n",
    "        h_re, w_re = image.shape[0], image.shape[1]\n",
    "\n",
    "        words = self.word_mask(img_size=(h_re, w_re), bboxes=words)\n",
    "        chars = self.char_mask(img_size=(h_re, w_re), bboxes=chars)\n",
    "\n",
    "        GT = {}\n",
    "        GT['image'] = image\n",
    "\n",
    "        # augmentation\n",
    "        GT['chars'] = chars\n",
    "        GT['words'] = words\n",
    "        GT = RandomCrop(crop_size=self.target_size)(GT)\n",
    "        GT = RandomHFlip(threshold=0.5)(GT)\n",
    "        GT = RandomRotate(max=10)(GT)\n",
    "        GT['image'] = color_jitter(GT['image'])\n",
    "\n",
    "        if len(GT['chars'].shape) == 2:\n",
    "            GT['chars'] = GT['chars'][np.newaxis, :, :]\n",
    "\n",
    "        if len(GT['words'].shape) == 2:\n",
    "            GT['words'] = GT['words'][np.newaxis, :, :]\n",
    "\n",
    "        GT['chars'] = torch.FloatTensor(GT['chars'])\n",
    "        GT['words'] = torch.FloatTensor(GT['words'])\n",
    "\n",
    "        GT['image'] = GT['image'].astype(np.float32)/255.\n",
    "        # Only mean/std normalization is applied on image\n",
    "        GT['image'] = normalizeMeanVariance(GT['image'])\n",
    "        GT['image'] = torch.FloatTensor(GT['image'].transpose((2, 0, 1)))\n",
    "        return GT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
